Building DAG of jobs...
Using shell: /usr/bin/bash
Provided cores: 1 (use --cores to define parallelism)
Rules claiming more threads will be scaled down.
Job counts:
	count	jobs
	1	compress_unassembled_reads
	1

[Thu Sep  8 13:12:19 2022]
rule compress_unassembled_reads:
    input: atavide.out/assemblies/unassembled_reads/SRR1237783.unassembled.R1.fastq, atavide.out/assemblies/unassembled_reads/SRR1237783.unassembled.R2.fastq, atavide.out/assemblies/unassembled_reads/SRR1237783.unassembled.singles.fastq
    output: atavide.out/assemblies/unassembled_reads/SRR1237783.unassembled.R1.fastq.gz, atavide.out/assemblies/unassembled_reads/SRR1237783.unassembled.R2.fastq.gz, atavide.out/assemblies/unassembled_reads/SRR1237783.unassembled.singles.fastq.gz
    jobid: 0
    wildcards: sample=SRR1237783
    resources: mem_mb=2000, time=1440, load_superfocus=0, load_kraken=0, load_onehundred=0


        for F in atavide.out/assemblies/unassembled_reads/SRR1237783.unassembled.R1.fastq atavide.out/assemblies/unassembled_reads/SRR1237783.unassembled.R2.fastq atavide.out/assemblies/unassembled_reads/SRR1237783.unassembled.singles.fastq; do gzip $F; done
        
[Thu Sep  8 13:12:21 2022]
Finished job 0.
1 of 1 steps (100%) done
