Building DAG of jobs...
Using shell: /usr/bin/bash
Provided cores: 8
Rules claiming more threads will be scaled down.
Job counts:
	count	jobs
	1	umapped_right_reads
	1

[Thu Sep  8 13:10:30 2022]
rule umapped_right_reads:
    input: atavide.out/assemblies/reads.contigs.1/SRR1237782.contigs.bam
    output: atavide.out/assemblies/unassembled_reads/SRR1237782.unassembled.R2.fastq
    jobid: 0
    wildcards: sample=SRR1237782
    threads: 8
    resources: mem_mb=32000, time=1440, load_superfocus=0, load_kraken=0, load_onehundred=0


        samtools view -@ 8 -h atavide.out/assemblies/reads.contigs.1/SRR1237782.contigs.bam | 
                awk 'BEGIN {FS="	"; OFS="	"} 
                {if (/^@/ && substr($2, 3, 1)==":") {print} 
                else if (and($2, 0x1) && and($2, 0x80) && 
                (and($2, 0x4) || and($2, 0x8))) {print}}'                 | samtools bam2fq -@ 8 > atavide.out/assemblies/unassembled_reads/SRR1237782.unassembled.R2.fastq
        
Activating conda environment: /scratch/user/nala0006/atavide-dev/atavide/atavide/atavide/workflow/conda/472d950e
[M::bam2fq_mainloop] discarded 0 singletons
[M::bam2fq_mainloop] processed 23883 reads
[Thu Sep  8 13:12:00 2022]
Finished job 0.
1 of 1 steps (100%) done
